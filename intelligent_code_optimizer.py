#!/usr/bin/env python3
"""
üîß INTELLIGENT CODE OPTIMIZATION ENGINE
Automated code improvement, refactoring suggestions, and performance optimization

üéØ PURPOSE: Automatically improve codebase quality and performance
‚ö†Ô∏è  NO FAKE WORK - ONLY REAL CODE IMPROVEMENTS WITH BACKUPS
"""

import os
import ast
import re
import sqlite3
import shutil
import time
import json
from datetime import datetime
from collections import defaultdict

class IntelligentCodeOptimizer:
    def __init__(self):
        self.workspace_path = "."
        self.backup_dir = "code_backups"
        self.db_path = "code_optimization.db"
        self.optimization_rules = self.load_optimization_rules()
        self.init_database()
        self.ensure_backup_dir()
    
    def init_database(self):
        """Initialize optimization tracking database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS optimizations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    file_path TEXT NOT NULL,
                    optimization_type TEXT NOT NULL,
                    description TEXT,
                    before_code TEXT,
                    after_code TEXT,
                    performance_impact REAL,
                    applied_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                    backup_path TEXT
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS refactor_suggestions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    file_path TEXT NOT NULL,
                    suggestion_type TEXT NOT NULL,
                    priority TEXT,
                    description TEXT,
                    estimated_effort TEXT,
                    potential_benefit TEXT,
                    created_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                    status TEXT DEFAULT 'pending'
                )
            ''')
            
            conn.commit()
            conn.close()
            print("‚úÖ Optimization database initialized")
        except Exception as e:
            print(f"‚ùå Database init error: {e}")
    
    def ensure_backup_dir(self):
        """Ensure backup directory exists"""
        if not os.path.exists(self.backup_dir):
            os.makedirs(self.backup_dir)
            print(f"üìÅ Created backup directory: {self.backup_dir}")
    
    def load_optimization_rules(self):
        """Load code optimization rules"""
        return {
            'performance': [
                {
                    'name': 'list_comprehension',
                    'pattern': r'for\s+(\w+)\s+in\s+(.+):\s*\n\s*(.+\.append\(.+\))',
                    'description': 'Convert loop with append to list comprehension',
                    'priority': 'medium'
                },
                {
                    'name': 'string_concatenation',
                    'pattern': r'(\w+)\s*\+=\s*["\'].*["\']',
                    'description': 'Use f-strings or join() for string concatenation',
                    'priority': 'medium'
                },
                {
                    'name': 'dict_get',
                    'pattern': r'if\s+(\w+)\s+in\s+(\w+):\s*\n\s*(.+)\s*=\s*\2\[\1\]',
                    'description': 'Use dict.get() instead of if-key check',
                    'priority': 'low'
                }
            ],
            'readability': [
                {
                    'name': 'long_functions',
                    'description': 'Break down functions with >50 lines',
                    'priority': 'high'
                },
                {
                    'name': 'complex_conditions',
                    'description': 'Simplify complex boolean expressions',
                    'priority': 'medium'
                }
            ],
            'maintainability': [
                {
                    'name': 'magic_numbers',
                    'pattern': r'(?<!["\'])\b\d{2,}\b(?!["\'])',
                    'description': 'Replace magic numbers with named constants',
                    'priority': 'medium'
                },
                {
                    'name': 'duplicate_code',
                    'description': 'Extract duplicate code blocks into functions',
                    'priority': 'high'
                }
            ]
        }
    
    def create_backup(self, file_path):
        """Create backup of file before optimization"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.basename(file_path)
            backup_path = os.path.join(self.backup_dir, f"{filename}.{timestamp}.backup")
            
            shutil.copy2(file_path, backup_path)
            print(f"üîÑ Backup created: {backup_path}")
            return backup_path
        except Exception as e:
            print(f"‚ö†Ô∏è  Backup failed for {file_path}: {e}")
            return None
    
    def analyze_function_complexity(self, node):
        """Analyze function complexity and suggest improvements"""
        suggestions = []
        
        # Check function length
        if hasattr(node, 'lineno') and hasattr(node, 'end_lineno'):
            func_length = node.end_lineno - node.lineno
            if func_length > 50:
                suggestions.append({
                    'type': 'function_length',
                    'priority': 'high',
                    'description': f'Function "{node.name}" is {func_length} lines long. Consider breaking it down.',
                    'estimated_effort': '2-4 hours',
                    'potential_benefit': 'Improved readability and testability'
                })
        
        # Check parameter count
        if len(node.args.args) > 5:
            suggestions.append({
                'type': 'parameter_count',
                'priority': 'medium',
                'description': f'Function "{node.name}" has {len(node.args.args)} parameters. Consider using a configuration object.',
                'estimated_effort': '1-2 hours',
                'potential_benefit': 'Better API design and maintainability'
            })
        
        # Check nested loops
        nested_loops = self.count_nested_loops(node)
        if nested_loops > 2:
            suggestions.append({
                'type': 'nested_loops',
                'priority': 'medium',
                'description': f'Function "{node.name}" has {nested_loops} levels of nested loops. Consider optimization.',
                'estimated_effort': '3-6 hours',
                'potential_benefit': 'Improved performance and readability'
            })
        
        return suggestions
    
    def count_nested_loops(self, node):
        """Count maximum nesting level of loops"""
        class LoopCounter(ast.NodeVisitor):
            def __init__(self):
                self.max_depth = 0
                self.current_depth = 0
            
            def visit_For(self, node):
                self.current_depth += 1
                self.max_depth = max(self.max_depth, self.current_depth)
                self.generic_visit(node)
                self.current_depth -= 1
            
            def visit_While(self, node):
                self.current_depth += 1
                self.max_depth = max(self.max_depth, self.current_depth)
                self.generic_visit(node)
                self.current_depth -= 1
        
        counter = LoopCounter()
        counter.visit(node)
        return counter.max_depth
    
    def optimize_imports(self, content):
        """Optimize import statements"""
        lines = content.split('\n')
        import_lines = []
        other_lines = []
        
        for line in lines:
            if line.strip().startswith(('import ', 'from ')):
                import_lines.append(line)
            else:
                other_lines.append(line)
        
        # Sort and deduplicate imports
        import_lines = sorted(list(set(import_lines)))
        
        # Group imports: standard library, third-party, local
        std_imports = []
        third_party_imports = []
        local_imports = []
        
        std_libs = {'os', 'sys', 'json', 'time', 'datetime', 'sqlite3', 'ast', 're', 'shutil', 'collections'}
        
        for imp in import_lines:
            if any(lib in imp for lib in std_libs):
                std_imports.append(imp)
            elif imp.startswith('from .') or 'local' in imp.lower():
                local_imports.append(imp)
            else:
                third_party_imports.append(imp)
        
        # Reconstruct content with optimized imports
        optimized_imports = []
        if std_imports:
            optimized_imports.extend(std_imports)
            optimized_imports.append('')
        if third_party_imports:
            optimized_imports.extend(third_party_imports)
            optimized_imports.append('')
        if local_imports:
            optimized_imports.extend(local_imports)
            optimized_imports.append('')
        
        return '\n'.join(optimized_imports + other_lines)
    
    def optimize_string_operations(self, content):
        """Optimize string operations"""
        optimizations = []
        
        # Replace string concatenation with f-strings
        pattern = r'(["\'])(.+?)\1\s*\+\s*str\((.+?)\)\s*\+\s*(["\'])(.+?)\4'
        matches = re.finditer(pattern, content)
        
        for match in matches:
            original = match.group(0)
            var = match.group(3)
            before_text = match.group(2)
            after_text = match.group(5)
            replacement = f'f"{before_text}{{{var}}}{after_text}"'
            
            optimizations.append({
                'type': 'string_formatting',
                'original': original,
                'optimized': replacement,
                'description': 'Convert string concatenation to f-string'
            })
        
        return optimizations
    
    def optimize_loop_operations(self, content):
        """Optimize loop operations"""
        optimizations = []
        
        # Find loops that can be converted to list comprehensions
        pattern = r'(\w+)\s*=\s*\[\]\s*\n\s*for\s+(\w+)\s+in\s+(.+?):\s*\n\s*\1\.append\((.+?)\)'
        matches = re.finditer(pattern, content, re.MULTILINE | re.DOTALL)
        
        for match in matches:
            original = match.group(0)
            list_var = match.group(1)
            item_var = match.group(2)
            iterable = match.group(3)
            expression = match.group(4)
            
            replacement = f'{list_var} = [{expression} for {item_var} in {iterable}]'
            
            optimizations.append({
                'type': 'list_comprehension',
                'original': original,
                'optimized': replacement,
                'description': 'Convert loop with append to list comprehension'
            })
        
        return optimizations
    
    def detect_code_smells(self, file_path):
        """Detect common code smells"""
        smells = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # Long parameter lists
            func_pattern = r'def\s+\w+\(([^)]{50,})\):'
            for match in re.finditer(func_pattern, content):
                smells.append({
                    'type': 'long_parameter_list',
                    'line': content[:match.start()].count('\n') + 1,
                    'description': 'Function has too many parameters',
                    'severity': 'medium'
                })
            
            # Magic numbers
            magic_pattern = r'(?<!["\'])\b(?<![\d.])\d{3,}\b(?![\d.]|["\'])'
            for match in re.finditer(magic_pattern, content):
                smells.append({
                    'type': 'magic_number',
                    'line': content[:match.start()].count('\n') + 1,
                    'description': f'Magic number: {match.group()}',
                    'severity': 'low'
                })
            
            # Long functions
            try:
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if hasattr(node, 'end_lineno') and node.end_lineno - node.lineno > 50:
                            smells.append({
                                'type': 'long_function',
                                'line': node.lineno,
                                'description': f'Function "{node.name}" is too long ({node.end_lineno - node.lineno} lines)',
                                'severity': 'high'
                            })
            except SyntaxError:
                pass
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Code smell detection failed for {file_path}: {e}")
        
        return smells
    
    def apply_automatic_optimizations(self, file_path):
        """Apply safe automatic optimizations"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                original_content = file.read()
            
            # Create backup first
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return False
            
            optimized_content = original_content
            applied_optimizations = []
            
            # Optimize imports
            optimized_content = self.optimize_imports(optimized_content)
            applied_optimizations.append('import_optimization')
            
            # Apply string optimizations
            string_opts = self.optimize_string_operations(optimized_content)
            for opt in string_opts:
                optimized_content = optimized_content.replace(opt['original'], opt['optimized'])
                applied_optimizations.append('string_optimization')
            
            # Apply loop optimizations
            loop_opts = self.optimize_loop_operations(optimized_content)
            for opt in loop_opts:
                optimized_content = optimized_content.replace(opt['original'], opt['optimized'])
                applied_optimizations.append('loop_optimization')
            
            # Write optimized content
            with open(file_path, 'w', encoding='utf-8') as file:
                file.write(optimized_content)
            
            # Log optimization
            self.log_optimization(file_path, applied_optimizations, original_content, 
                                optimized_content, backup_path)
            
            print(f"‚úÖ Optimized: {file_path} ({len(applied_optimizations)} improvements)")
            return True
            
        except Exception as e:
            print(f"‚ùå Optimization failed for {file_path}: {e}")
            return False
    
    def log_optimization(self, file_path, optimizations, before_code, after_code, backup_path):
        """Log optimization details to database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO optimizations (
                    file_path, optimization_type, description, 
                    before_code, after_code, backup_path
                ) VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                file_path,
                ', '.join(optimizations),
                f"Applied {len(optimizations)} optimizations",
                before_code[:1000],  # Truncate for storage
                after_code[:1000],
                backup_path
            ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to log optimization: {e}")
    
    def generate_refactor_suggestions(self, file_path):
        """Generate comprehensive refactoring suggestions"""
        suggestions = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # Parse AST for detailed analysis
            try:
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        func_suggestions = self.analyze_function_complexity(node)
                        suggestions.extend(func_suggestions)
                        
            except SyntaxError as e:
                suggestions.append({
                    'type': 'syntax_error',
                    'priority': 'critical',
                    'description': f'Syntax error: {e}',
                    'estimated_effort': '30 minutes',
                    'potential_benefit': 'Code will execute without errors'
                })
            
            # Detect code smells
            smells = self.detect_code_smells(file_path)
            for smell in smells:
                suggestions.append({
                    'type': smell['type'],
                    'priority': smell['severity'],
                    'description': smell['description'],
                    'estimated_effort': self.estimate_effort(smell['type']),
                    'potential_benefit': self.get_benefit_description(smell['type'])
                })
            
            # Store suggestions in database
            self.store_suggestions(file_path, suggestions)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Suggestion generation failed for {file_path}: {e}")
        
        return suggestions
    
    def estimate_effort(self, issue_type):
        """Estimate effort required for different types of improvements"""
        effort_map = {
            'long_function': '2-4 hours',
            'magic_number': '15-30 minutes',
            'long_parameter_list': '1-2 hours',
            'nested_loops': '3-6 hours',
            'syntax_error': '30 minutes',
            'default': '1 hour'
        }
        return effort_map.get(issue_type, effort_map['default'])
    
    def get_benefit_description(self, issue_type):
        """Get benefit description for different improvements"""
        benefit_map = {
            'long_function': 'Improved readability, testability, and maintainability',
            'magic_number': 'Better code clarity and easier configuration management',
            'long_parameter_list': 'Cleaner API design and reduced coupling',
            'nested_loops': 'Better performance and reduced complexity',
            'syntax_error': 'Code execution without errors',
            'default': 'Improved code quality'
        }
        return benefit_map.get(issue_type, benefit_map['default'])
    
    def store_suggestions(self, file_path, suggestions):
        """Store refactoring suggestions in database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for suggestion in suggestions:
                cursor.execute('''
                    INSERT INTO refactor_suggestions (
                        file_path, suggestion_type, priority, description,
                        estimated_effort, potential_benefit
                    ) VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    file_path,
                    suggestion['type'],
                    suggestion['priority'],
                    suggestion['description'],
                    suggestion['estimated_effort'],
                    suggestion['potential_benefit']
                ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to store suggestions: {e}")
    
    def execute_optimization_cycle(self):
        """Execute full optimization cycle on codebase"""
        print("üîß EXECUTING INTELLIGENT CODE OPTIMIZATION")
        print("=" * 60)
        
        start_time = time.time()
        results = {
            'files_processed': 0,
            'files_optimized': 0,
            'optimizations_applied': 0,
            'suggestions_generated': 0,
            'errors': []
        }
        
        # Process all Python files
        for root, dirs, files in os.walk(self.workspace_path):
            # Skip backup directory
            if self.backup_dir in root:
                continue
                
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    results['files_processed'] += 1
                    
                    try:
                        # Apply automatic optimizations
                        if self.apply_automatic_optimizations(file_path):
                            results['files_optimized'] += 1
                        
                        # Generate refactoring suggestions
                        suggestions = self.generate_refactor_suggestions(file_path)
                        results['suggestions_generated'] += len(suggestions)
                        
                    except Exception as e:
                        error_msg = f"Error processing {file_path}: {e}"
                        results['errors'].append(error_msg)
                        print(f"‚ùå {error_msg}")
        
        # Generate summary report
        execution_time = time.time() - start_time
        results['execution_time'] = round(execution_time, 2)
        
        print(f"\n‚úÖ OPTIMIZATION COMPLETE")
        print(f"üìÅ Files processed: {results['files_processed']}")
        print(f"üîß Files optimized: {results['files_optimized']}")
        print(f"üí° Suggestions generated: {results['suggestions_generated']}")
        print(f"‚è±Ô∏è  Execution time: {execution_time:.2f}s")
        
        if results['errors']:
            print(f"‚ö†Ô∏è  Errors encountered: {len(results['errors'])}")
        
        # Save results
        self.save_optimization_report(results)
        
        return results
    
    def save_optimization_report(self, results):
        """Save optimization report"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"optimization_report_{timestamp}.json"
            
            with open(filename, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            
            print(f"üìÑ Report saved to: {filename}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to save report: {e}")


def main():
    """Main execution function"""
    print("üöÄ STARTING INTELLIGENT CODE OPTIMIZATION ENGINE")
    print("üéØ FOCUS: Real code improvements with backup protection")
    print("‚ö†Ô∏è  NO FAKE WORK - ONLY GENUINE CODE OPTIMIZATION")
    print("=" * 70)
    
    optimizer = IntelligentCodeOptimizer()
    
    try:
        results = optimizer.execute_optimization_cycle()
        
        print("\nüìä OPTIMIZATION SUMMARY:")
        print("-" * 40)
        print(f"‚úÖ Successfully processed {results['files_processed']} Python files")
        print(f"üîß Applied optimizations to {results['files_optimized']} files")
        print(f"üí° Generated {results['suggestions_generated']} improvement suggestions")
        
        if results['errors']:
            print(f"‚ö†Ô∏è  Encountered {len(results['errors'])} errors during processing")
        
        print(f"\nüéØ REAL DEVELOPMENT WORK COMPLETED!")
        print(f"‚è±Ô∏è  Total execution time: {results['execution_time']}s")
        
    except Exception as e:
        print(f"‚ùå Optimization engine failed: {e}")


if __name__ == "__main__":
    main()
